1. Google cloud storage, make bucket: bk-pghoard

2. Instaluj pghoard (install pghoard)
  + python3-psycopg2, python3-requests, python3-snappy, python3-systemd
  + cloud storage package(s), see github.com/ohmu/pghoard
  +? python3-flake8, pylint3, python3-pytest

3. Instaluj gsutil (install gsutil):
  pip install gsutil
  gsutil config

4. github zvolsky/var_lib_pghoard -> /var/lib/pghoard
  Uprav postgres verzi a port (9.6, 5433) ve všech souborech. Uprav databáze v bin/my_pg_dump.sh. Případně změň mzDebian -> xxx.
  (Update postgres version and port (9.6, 5433) in all files. Set proper databases in bin/my_pg_dump.sh. Optionally rename mzDebian -> xxx.)

5. Personalizuj xxxxxx v /var/lib/pghoard/*.json (pg-backup-xxxxxxx.json vygenerujte v Google consoli).
  (Personalize xxxxxx settings in /var/lib/pghoard/*.json (pg-backup-xxxxxxx.json will generate Google console for you).)

6. 
  chown -R postgres:postgres /var/lib/pghoard
  chown -R root:root /var/lib/pghoard/mzDebian/bin

7.
  /etc/postgresql/9.6/main/pg_hba.conf:
    # TYPE  DATABASE     USER     ADDRESS       METHOD
    local   all          pghoard                md5
    local   replication  pghoard                md5
    host    replication  pghoard  127.0.0.1/32  md5
  /etc/postgresql/9.6/main/postgresql.conf:
    wal_level = replica (or 'archive' if not supported)
    max_wal_senders = 3
    max_replication_slots = 2
    archive_mode = off
    archive_timeout = 600 # how often close wal/xlog file

8. Zálohuj /etc/.../*.conf/ do conf/ a do cloudu.
  (Backup /etc/.../*.conf/ into conf/ and into cloud.)

9. CREATE USER pghoard PASSWORD 'XXXXXXXXXX' REPLICATION;

10.
  systemctl enable pghoard.service
  systemctl start pghoard

11.
  check basebackup in the cloud
  next day check pg_dump backup in the cloud
    does pg_dump create non-empty files?
      if empty, it probably ask password:
        check /var/lib/postgresql/.pgpass
          chown postgres:postgres /var/lib/postgresql/.pgpass
          chmod 600 /var/lib/postgresql/.pgpass
          content:
            localhost:5433:*:postgres:password
            127.0.0.1:5433:*.postgres:password
            127.0.0.1:5433:replication:pghoard:password
  how to set the password:
    su - postgres
    psql -p 5433
    \password
    \q

12. Cron, user postgres:
  su - postgres
  crontab -e
    30 3 * * * /var/lib/pghoard/mzDebian/bin/my_pg_dump.sh
    */8 * * * * /var/lib/postgresql/Dropbox/dropbox.py start -i

13. Dropbox
  register Dropbox (I use admin@server.xx, where on Wedos I have redirect to my standard address); https://www.dropbox.com/getspace
  see: www.dropbox.com/install (install for Linux; Dropbox Headless Install via command line)
    su - postgres
    cd ~ && wget -O - "https://www.dropbox.com/download?plat=lnx.x86_64" | tar xzf -
    ~/.dropbox-dist/dropboxd
  copy the offered link into any browser (can run on other machine) and fill required; after that server displays that it is connected; directory ~/Dropbox now exists.
  get pg_xlog/ into ~/Dropbox folder:
    assuming pghoard+receivexlog is used
    ln -s /var/lib/pghoard/metadata/mzDebian/xlog_incoming/ /var/lib/postgresql/Dropbox/mzDebian/ (will create xlog_incoming/ inside)
  (into ~/Dropbox or so) download the dropbox.py (dropbox.com/install, bellow, Download python script)
    user can be root
    chmod +x /var/lib/postgresql/Dropbox/dropbox.py
  (su - postgres:) ./dropbox.py start -i
    maybe limit upload speed kB/s (but dropbox uses some auto handling): ./dropbox.py throttle unlimited 512
  use some auto-starting (like */8 in cron -- stupid but working)


PGDUMP RESTORE

Pokud cluster běží, vypínáme ho v pgd_restore.
Starý cluster je odstraněn zcela a proto kopírujeme konfigurace do /etc/...
Pokud je lokální záloha poškozena, z cloudu ji nejprve obnov manuálně.

If cluster is still working, we shut them down in pgd_restore.
Old cluster is completely removed and .conf files are copied from backup into /etc/...
If local files are lost, restore them from cloud first by hand.

./pgd_restore.sh         -- (zahrnuje i případné odstavení serveru; contains stopping of the server too)
./pgh_restore_after.sh   -- basebackup pro pghoard (bb for pgh)


PGHOARD RESTORE

Pokud cluster a/nebo pghoard běží, vypínáme ho v pgh_restore_before.
Neřešíme /etc/... Pokud je konfigurace poškozena (a vytváříš úplně nový cluster), obnov ji z conf/ nebo cloudu

If cluster and/or pghoard is still working, we shut them down in pgh_restore_before.
We do not touch /etc/... If it is damaged (and you build a completely new cluster), copy configs from conf/ or from cloud.


./pgh_restore_before.sh  -- odstavení serveru (stopping of the server+pghoard)
./pgh_restore_1.sh       -- rozbalení basebackupu (apply basebackup)
Download .partial from Dropbox into metadata/site/xlog_incoming + remove extension .partial
./pgh_restore_2.sh       -- aplikovat pozdější změny (apply wal logs - changes after basebackup)
./pgh_restore_after.sh   -- nový basebackup; je potřeba, když aplikujeme .partial (new basebackup; required if we apply the .partial file)
